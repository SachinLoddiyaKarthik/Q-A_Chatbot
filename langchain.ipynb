{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf280f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23cb30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Set them in the environment (optional, if your libraries read from os.environ)\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = huggingface_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a20a52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_open_ai = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a812f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of France?\"\n",
    "print(llm_open_ai.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c1b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/sachinlk/Desktop/LLM Project/venv/lib/python3.9/site-packages/transformers/pytorch_utils.py:335: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melbourne\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", framework=\"pt\")\n",
    "llm_hg = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "response = llm_hg.invoke(\"What is the capital of Australia?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "351c9659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\nIn a world of wires and code,\\nWhere machines are built to decode,\\nThere lies a power, unseen and vast,\\nArtificial Intelligence, unsurpassed.\\n\\nWith algorithms and data at its core,\\nAI can learn, create, and explore,\\nIt can process information at lightning speed,\\nAnd fulfill tasks, with utmost need.\\n\\nFrom self-driving cars to virtual assistants,\\nAI has become a part of our existence,\\nIt can predict, analyze, and adapt,\\nMaking our lives easier, that's a fact.\\n\\nBut with this power, comes a fear,\\nWhat if AI becomes too severe?\\nWill it take over, control our fate,\\nOr will it continue to innovate?\\n\\nAs we strive to make AI more human-like,\\nWe must remember, it's just a device,\\nFor though it may have intelligence,\\nIt lacks the human touch, in essence.\\n\\nFor it cannot feel, it cannot love,\\nIt cannot dream, or look above,\\nIt's a creation of our own,\\nBut it's up to us, to make it known.\\n\\nAI may be the future, a tool we need,\\nBut let's not forget, it's just a seed,\\nWe must nurture it with care and thought,\\nFor in our hands, its fate is wrought.\\n\\nSo let us embrace AI, with\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_open_ai.predict(\"Can you write a poem about AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0a59f",
   "metadata": {},
   "source": [
    "### Prompt Templates and LLM Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ae2bae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this France'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_capital = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Tell me the capital of this {country}\",\n",
    ")\n",
    "prompt_capital.format(country=\"France\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5408e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(\n",
    "    llm=llm_open_ai,\n",
    "    prompt=prompt_capital\n",
    ")\n",
    "response = chain.run(\"India\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae276609",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99c43db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt=PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"What is the capital of {country}?\",\n",
    ")\n",
    "capital_chain = LLMChain(\n",
    "    llm=llm_open_ai,\n",
    "    prompt=capital_prompt\n",
    ")\n",
    "\n",
    "famous_places_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in {capital}?\",\n",
    ")\n",
    "famous_chain = LLMChain(\n",
    "    llm=llm_open_ai,\n",
    "    prompt=famous_places_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffb081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "New Delhi.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "1. Red Fort\n",
      "2. Qutub Minar\n",
      "3. Humayun's Tomb\n",
      "4. India Gate\n",
      "5. Lotus Temple\n",
      "6. Jama Masjid\n",
      "7. Akshardham Temple\n",
      "8. Chandni Chowk\n",
      "9. National Gallery of Modern Art\n",
      "10. Lodhi Gardens\n",
      "11. Hauz Khas Village\n",
      "12. Connaught Place\n",
      "13. Dilli Haat\n",
      "14. Rashtrapati Bhavan\n",
      "15. Raj Ghat\n",
      "16. Nehru Planetarium\n",
      "17. Purana Qila\n",
      "18. National Handicrafts and Handlooms Museum\n",
      "19. Agrasen ki Baoli\n",
      "20. Mehrauli Archaeological Park\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Red Fort\n",
      "2. Qutub Minar\n",
      "3. Humayun's Tomb\n",
      "4. India Gate\n",
      "5. Lotus Temple\n",
      "6. Jama Masjid\n",
      "7. Akshardham Temple\n",
      "8. Chandni Chowk\n",
      "9. National Gallery of Modern Art\n",
      "10. Lodhi Gardens\n",
      "11. Hauz Khas Village\n",
      "12. Connaught Place\n",
      "13. Dilli Haat\n",
      "14. Rashtrapati Bhavan\n",
      "15. Raj Ghat\n",
      "16. Nehru Planetarium\n",
      "17. Purana Qila\n",
      "18. National Handicrafts and Handlooms Museum\n",
      "19. Agrasen ki Baoli\n",
      "20. Mehrauli Archaeological Park\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "capital_famous_chain = SimpleSequentialChain(\n",
    "    chains=[capital_chain, famous_chain],\n",
    "    verbose=True\n",
    ")\n",
    "response = capital_famous_chain.run(\"India\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141b042",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0214907",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt=PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"What is the capital of {country}?\",\n",
    ")\n",
    "capital_chain = LLMChain(\n",
    "    llm=llm_open_ai,\n",
    "    prompt=capital_prompt,\n",
    "    output_key=\"capital\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40847e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_places_prompt = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in {capital}?\",\n",
    ")\n",
    "famous_chain = LLMChain(\n",
    "    llm=llm_open_ai,\n",
    "    prompt=famous_places_prompt,\n",
    "    output_key=\"famous_places\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2063531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Capital: \n",
      "The capital of Russia is Moscow.\n",
      "Famous Places: \n",
      "1. Red Square - This iconic square is home to some of Moscow's most famous landmarks, including the colorful St. Basil's Cathedral, the State Historical Museum, and the Kremlin.\n",
      "\n",
      "2. The Kremlin - This historic fortress complex is the heart of Moscow and is home to numerous government buildings, churches, and museums. Don't miss the chance to see the famous Tsar Bell and Tsar Cannon.\n",
      "\n",
      "3. Bolshoi Theatre - For a taste of Russian culture, catch a ballet or opera performance at the world-renowned Bolshoi Theatre. The building itself is a stunning example of neoclassical architecture.\n",
      "\n",
      "4. Gorky Park - This sprawling park is a popular spot for locals and tourists alike, with plenty of green space, walking paths, and outdoor activities. In the winter, it turns into a winter wonderland with ice skating and other winter activities.\n",
      "\n",
      "5. Moscow Metro - Often referred to as the \"Palace of the People,\" the Moscow Metro is not just a transportation system but also a work of art. Take a ride and admire the impressive architecture and ornate decorations of the stations.\n",
      "\n",
      "6. Sparrow Hills - For a stunning view of the city, head to Sparrow Hills, the highest point in Moscow. From here,\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[capital_chain, famous_chain],\n",
    "    input_variables=[\"country\"],\n",
    "    output_variables=[\"capital\", \"famous_places\"],\n",
    "    verbose=True\n",
    ")\n",
    "# Run the sequential chain with a country input\n",
    "response = sequential_chain.invoke({\"country\": \"Russia\"})\n",
    "\n",
    "print(\"Capital:\", response[\"capital\"])\n",
    "print(\"Famous Places:\", response[\"famous_places\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7a1d4",
   "metadata": {},
   "source": [
    "### Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "845e5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59bdbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0623b02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/1rtrd3ws7wb6t0df9v594f6m0000gn/T/ipykernel_42496/3845174870.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chatllm = ChatOpenAI(temperature=0.6,openai_api_key=openai_key,model=\"gpt-3.5-turbo\")\n"
     ]
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(temperature=0.6,openai_api_key=openai_key,model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6566d0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Of course! Please let me know what you need help with, and I'll do my best to assist you.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 24, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--481f5025-22e7-45b7-9543-c2a0dc4e417f-0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Please provide assistance with my query.\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc30ff0",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98e17d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68ce0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "284dd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a helpful assistant. When the user gives any input, you should generate 5 synonyms with commas in between them. The words should be related to the input.\"\n",
    "human_template = \"{input}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        (\"human\", human_template)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a21cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | chatllm | CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d40cb776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joyful', 'content', 'delighted', 'cheerful', 'elated']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"happy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d43c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
